"""
Database models for Academic Paper MCP v3.3

Schema:
- papers: Main paper metadata + full_text + keywords + domain
- domains: Self-organizing domain taxonomy
- sections: Document structure (intro, methodology, etc.)
- chunks: Page-based chunks for retrieval
- extractions: Verbatim extractions from LLM
"""

from datetime import datetime
from enum import Enum
from typing import Optional
from contextlib import contextmanager

from sqlalchemy import (
    create_engine,
    Text,
    JSON,
    ForeignKey,
    Index,
    event,
    func
)
from sqlalchemy.orm import (
    DeclarativeBase,
    Mapped,
    mapped_column,
    relationship,
    Session,
    sessionmaker
)


class Base(DeclarativeBase):
    pass


class ProcessingStatus(str, Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"


class Domain(Base):
    """
    Self-organizing domain taxonomy.
    
    Domains are created by LLM during import, reused when similar.
    Specific and research-actionable (not broad categories).
    """
    __tablename__ = "domains"
    
    domain_id: Mapped[int] = mapped_column(primary_key=True, autoincrement=True)
    
    # Domain name (specific, research-actionable)
    name: Mapped[str] = mapped_column(unique=True, index=True)
    # e.g., "microkernel formal verification using Isabelle"
    
    # Stats
    paper_count: Mapped[int] = mapped_column(default=0)
    
    # When created
    created_at: Mapped[datetime] = mapped_column(default=datetime.utcnow)
    
    # Optional: broader category for grouping (UI only, not used in search)
    parent_category: Mapped[Optional[str]] = mapped_column(default=None)
    # e.g., "formal verification" - for grouping only
    
    def __repr__(self) -> str:
        return f"Domain(name={self.name!r}, papers={self.paper_count})"


class Paper(Base):
    """
    Main paper record.
    
    Metadata comes from Zotero (trusted).
    full_text is always preserved for verification.
    """
    __tablename__ = "papers"
    
    # Primary identifier (= BibTeX citation key)
    paper_id: Mapped[str] = mapped_column(primary_key=True)
    # e.g., "lyons_2023_mixedcriticality"
    
    # Zotero linking
    zotero_key: Mapped[Optional[str]] = mapped_column(index=True)
    # e.g., "HTJHSCCZ" (storage folder)
    zotero_item_id: Mapped[Optional[int]]
    zotero_collections: Mapped[list[str]] = mapped_column(JSON, default=list)
    # e.g., ["PhD Research", "seL4 Papers"]
    
    # Deduplication
    file_path: Mapped[str]
    file_hash: Mapped[Optional[str]] = mapped_column(index=True)
    # SHA256 hash for detecting same PDF from different sources
    
    # Metadata FROM ZOTERO (trusted, not LLM-extracted)
    title: Mapped[Optional[str]] = mapped_column(Text)
    authors: Mapped[list[str]] = mapped_column(JSON, default=list)
    abstract: Mapped[Optional[str]] = mapped_column(Text)
    publication_date: Mapped[Optional[str]]
    year: Mapped[Optional[int]] = mapped_column(index=True)
    journal_or_venue: Mapped[Optional[str]] = mapped_column(index=True)
    doi: Mapped[Optional[str]]
    
    # === NEW IN v3.3: Keywords & Domain ===
    
    # Keywords extracted from paper or LLM
    keywords: Mapped[list[str]] = mapped_column(JSON, default=list)
    # e.g., ["formal verification", "seL4", "microkernel"]
    
    keywords_source: Mapped[Optional[str]] = mapped_column(default=None)
    # "paper" = extracted from PDF (trustworthy)
    # "llm" = generated by LLM (use with caution)
    
    # Single specific domain (self-organizing taxonomy)
    domain: Mapped[Optional[str]] = mapped_column(index=True, default=None)
    # e.g., "microkernel formal verification using Isabelle"
    
    # === END NEW ===
    
    # Document stats
    page_count: Mapped[Optional[int]]
    word_count: Mapped[Optional[int]]
    
    # Full text storage (ALWAYS preserved for verification)
    full_text: Mapped[Optional[str]] = mapped_column(Text)
    
    # Processing metadata
    imported_at: Mapped[datetime] = mapped_column(default=datetime.utcnow)
    processed_at: Mapped[Optional[datetime]]
    processing_status: Mapped[ProcessingStatus] = mapped_column(
        default=ProcessingStatus.PENDING
    )
    processing_model: Mapped[Optional[str]]
    processing_version: Mapped[str] = mapped_column(default="3.3")
    
    # Relationships
    sections: Mapped[list["Section"]] = relationship(
        back_populates="paper",
        cascade="all, delete-orphan",
        order_by="Section.page_start"
    )
    chunks: Mapped[list["Chunk"]] = relationship(
        back_populates="paper",
        cascade="all, delete-orphan",
        order_by="Chunk.page_number"
    )
    extraction: Mapped[Optional["Extraction"]] = relationship(
        back_populates="paper",
        uselist=False,
        cascade="all, delete-orphan"
    )
    
    __table_args__ = (
        Index("idx_papers_status", "processing_status"),
        Index("idx_papers_zotero", "zotero_key"),
        Index("idx_papers_domain", "domain"),
        Index("idx_papers_venue", "journal_or_venue"),
        Index("idx_papers_year", "year"),
    )
    
    def __repr__(self) -> str:
        return f"Paper(id={self.paper_id!r}, title={self.title!r})"
    
    @property
    def citation_key(self) -> str:
        """Alias for paper_id (BibTeX cite key)."""
        return self.paper_id


class Section(Base):
    """
    Document section detected by LLM.
    
    Provides structure: introduction, methodology, results, etc.
    Even if detection is imperfect, chunks contain the real content.
    """
    __tablename__ = "sections"
    
    section_id: Mapped[str] = mapped_column(primary_key=True)
    # e.g., "lyons_2023_mixedcriticality_sec_3"
    
    paper_id: Mapped[str] = mapped_column(
        ForeignKey("papers.paper_id", ondelete="CASCADE"),
        index=True
    )
    
    # Section identification
    section_type: Mapped[str]
    # abstract | introduction | background | literature_review |
    # methodology | results | discussion | conclusion | 
    # references | appendix | unknown
    
    section_title: Mapped[Optional[str]]
    # Original heading text, e.g., "3.1 Experimental Setup"
    
    section_index: Mapped[int]
    # Order in document (0, 1, 2, ...)
    
    # Location in document
    page_start: Mapped[int]
    page_end: Mapped[int]
    char_start: Mapped[int]   # Position in full_text
    char_end: Mapped[int]
    
    # LLM-generated content
    summary: Mapped[Optional[str]] = mapped_column(Text)
    # 2-3 sentence summary (use with caution)
    
    key_points_verbatim: Mapped[list[dict]] = mapped_column(JSON, default=list)
    # [{"text": "exact quote from paper", "page": 5}, ...]
    # TRUSTWORTHY - copied directly from paper
    
    # Detection metadata
    detection_method: Mapped[str] = mapped_column(default="llm")
    # "llm" or "page_fallback"
    confidence: Mapped[float] = mapped_column(default=0.7)
    
    # Relationships
    paper: Mapped["Paper"] = relationship(back_populates="sections")
    chunks: Mapped[list["Chunk"]] = relationship(
        back_populates="section",
        order_by="Chunk.page_number"
    )
    
    __table_args__ = (
        Index("idx_sections_type", "section_type"),
    )
    
    def __repr__(self) -> str:
        return f"Section(id={self.section_id!r}, type={self.section_type!r})"
    
    def get_text(self, full_text: str) -> str:
        """Get section text from paper's full_text."""
        return full_text[self.char_start:self.char_end]


class Chunk(Base):
    """
    Page-based chunk for retrieval.
    
    1 page = 1 chunk. Simple, predictable, PDF-aligned.
    """
    __tablename__ = "chunks"
    
    chunk_id: Mapped[str] = mapped_column(primary_key=True)
    # e.g., "lyons_2023_mixedcriticality_page_5"
    
    paper_id: Mapped[str] = mapped_column(
        ForeignKey("papers.paper_id", ondelete="CASCADE"),
        index=True
    )
    
    section_id: Mapped[Optional[str]] = mapped_column(
        ForeignKey("sections.section_id", ondelete="SET NULL"),
        index=True
    )
    # May be null if section detection failed
    
    # Page info
    page_number: Mapped[int]
    
    # Position in full_text (for verification)
    char_start: Mapped[int]
    char_end: Mapped[int]
    
    # Content (stored for fast retrieval)
    content: Mapped[str] = mapped_column(Text)
    word_count: Mapped[int]
    
    # Relationships
    paper: Mapped["Paper"] = relationship(back_populates="chunks")
    section: Mapped[Optional["Section"]] = relationship(back_populates="chunks")
    
    __table_args__ = (
        Index("idx_chunks_page", "paper_id", "page_number"),
    )
    
    def __repr__(self) -> str:
        return f"Chunk(id={self.chunk_id!r}, page={self.page_number})"
    
    def verify_content(self, full_text: str) -> bool:
        """Verify chunk content matches full_text."""
        return self.content == full_text[self.char_start:self.char_end]


class Extraction(Base):
    """
    LLM extractions from a paper.
    
    v3.3 PHILOSOPHY: Copy original text, don't summarize.
    - *_verbatim fields: Exact text from paper (TRUSTWORTHY)
    - *_summary fields: LLM summaries (use with caution)
    
    Note: keywords and domain moved to Paper table in v3.3
    """
    __tablename__ = "extractions"
    
    paper_id: Mapped[str] = mapped_column(
        ForeignKey("papers.paper_id", ondelete="CASCADE"),
        primary_key=True
    )
    
    # === VERBATIM EXTRACTIONS (trustworthy) ===
    
    # Methodology - exact paragraphs copied from paper
    methodology_verbatim: Mapped[Optional[str]] = mapped_column(Text)
    evaluation_setup_verbatim: Mapped[Optional[str]] = mapped_column(Text)
    
    # Contributions - with section/page tracking
    contributions_verbatim: Mapped[list[dict]] = mapped_column(JSON, default=list)
    # [{"text": "We present seL4...", "section": "Abstract", "page": 1}]
    
    # Results - exact sentences reporting findings
    results_verbatim: Mapped[list[dict]] = mapped_column(JSON, default=list)
    # [{"text": "The measured latency was 9400ns", "section": "Evaluation", "page": 8}]
    
    # Statistics - ONLY if they exist in paper
    statistics_verbatim: Mapped[list[dict]] = mapped_column(JSON, default=list)
    # [{"text": "30x faster than...", "section": "Results", "page": 10}]
    # EMPTY if paper has no statistics (never fabricate!)
    
    # Limitations - what AUTHORS wrote, not inferred
    limitations_verbatim: Mapped[list[dict]] = mapped_column(JSON, default=list)
    # [{"text": "Our approach does not handle...", "section": "Discussion", "page": 12}]
    
    # Future work - author stated
    future_work_verbatim: Mapped[list[dict]] = mapped_column(JSON, default=list)
    
    # === LLM SUMMARIES (use with caution) ===
    
    methodology_summary: Mapped[Optional[str]] = mapped_column(Text)
    # Brief summary - may miss details or misinterpret
    
    # Classification (kept for backward compatibility, but domain/keywords now in Paper)
    methodology_type: Mapped[Optional[str]]
    # empirical | theoretical | design-science | survey | formal-methods
    paper_type: Mapped[Optional[str]]
    # systems-paper | empirical-study | survey | position-paper | formal-verification
    
    # Software/tools mentioned
    software_tools: Mapped[list[str]] = mapped_column(JSON, default=list)
    
    # Relationship
    paper: Mapped["Paper"] = relationship(back_populates="extraction")
    
    def __repr__(self) -> str:
        return f"Extraction(paper_id={self.paper_id!r})"


class Database:
    """Database connection manager."""
    
    def __init__(self, url: str = "sqlite:///data/papers.db"):
        self.engine = create_engine(url, echo=False)
        self.SessionLocal = sessionmaker(bind=self.engine)
        
        # Enable foreign keys for SQLite
        if "sqlite" in url:
            @event.listens_for(self.engine, "connect")
            def set_sqlite_pragma(dbapi_connection, connection_record):
                cursor = dbapi_connection.cursor()
                cursor.execute("PRAGMA foreign_keys=ON")
                cursor.close()
    
    def create_tables(self):
        """Create all tables."""
        Base.metadata.create_all(self.engine)
    
    def drop_tables(self):
        """Drop all tables."""
        Base.metadata.drop_all(self.engine)
    
    @contextmanager
    def get_session(self) -> Session:
        """Get database session with automatic cleanup."""
        session = self.SessionLocal()
        try:
            yield session
            session.commit()
        except Exception:
            session.rollback()
            raise
        finally:
            session.close()


# Section type constants
class SectionType:
    ABSTRACT = "abstract"
    INTRODUCTION = "introduction"
    BACKGROUND = "background"
    LITERATURE_REVIEW = "literature_review"
    METHODOLOGY = "methodology"
    RESULTS = "results"
    DISCUSSION = "discussion"
    CONCLUSION = "conclusion"
    REFERENCES = "references"
    APPENDIX = "appendix"
    UNKNOWN = "unknown"
    
    @classmethod
    def all_types(cls) -> list[str]:
        return [
            cls.ABSTRACT, cls.INTRODUCTION, cls.BACKGROUND,
            cls.LITERATURE_REVIEW, cls.METHODOLOGY, cls.RESULTS,
            cls.DISCUSSION, cls.CONCLUSION, cls.REFERENCES,
            cls.APPENDIX, cls.UNKNOWN
        ]
